{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/AnimateDiff-Lightning-jupyter/blob/main/AnimateDiff_Lightning_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers\n",
        "\n",
        "import torch\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from diffusers.utils import export_to_gif\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.float16\n",
        "\n",
        "step = 4  # Options: [1,2,4,8]\n",
        "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
        "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
        "base = \"emilianJR/epiCRealism\"  # Choose to your favorite base model.\n",
        "\n",
        "adapter = MotionAdapter().to(device, dtype)\n",
        "adapter.load_state_dict(load_file(hf_hub_download(repo ,ckpt), device=device))\n",
        "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(prompt=\"A girl smiling\", guidance_scale=1.0, num_inference_steps=step)\n",
        "export_to_gif(output.frames[0], \"animation.gif\")\n",
        "from IPython.display import Image\n",
        "Image(open('/content/animation.gif', 'rb').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import imageio\n",
        "\n",
        "def export_to_video(\n",
        "    video_frames: Union[List[np.ndarray], List[PIL.Image.Image]], output_video_path: str = None, fps: int = 10\n",
        ") -> str:\n",
        "    if output_video_path is None:\n",
        "        output_video_path = tempfile.NamedTemporaryFile(suffix=\".mp4\").name\n",
        "    if isinstance(video_frames[0], np.ndarray):\n",
        "        video_frames = [(frame * 255).astype(np.uint8) for frame in video_frames]\n",
        "    elif isinstance(video_frames[0], PIL.Image.Image):\n",
        "        video_frames = [np.array(frame) for frame in video_frames]\n",
        "    writer = imageio.get_writer(output_video_path, fps=fps)\n",
        "    for frame in video_frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    return output_video_path\n",
        "\n",
        "export_to_video(output.frames[0], \"animation.mp4\")\n",
        "from IPython.display import Video\n",
        "Video(\"/content/animation.mp4\", embed=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
